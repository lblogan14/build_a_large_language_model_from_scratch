{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c2facd",
   "metadata": {},
   "source": [
    "# Chapter 4: Implementing a GPT Model from Scratch to Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b63ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.8\n",
      "torch version: 2.9.1\n",
      "tiktoken version: 0.12.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"matplotlib version:\", version(\"matplotlib\"))\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d59099",
   "metadata": {},
   "source": [
    "## 4.1 Coding an LLM Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b49944",
   "metadata": {},
   "source": [
    "*Generative Pre-trained Transformer (GPT)* models are large deep neural network architectures designed to generate human-like text one token at a time.\n",
    "\n",
    "In this chapter, we will focus on building a smaller version of GPT-2 model from scratch using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec241cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration details for the 124M parameter GPT-2 model\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,        # Vocabulary size (same as used by the BPE tokenizer)\n",
    "    \"context_length\": 1024,     # Context length (maximum number of tokens in input via positional encoding)\n",
    "    \"emb_dim\": 768,             # Embedding dimension\n",
    "    \"n_heads\": 12,              # Number of attention heads (number of attention heads in multi-head attention)\n",
    "    \"n_layers\": 12,             # Number of transformer layers (number of transformer blocks)\n",
    "    \"drop_rate\": 0.1,           # Dropout rate (10% dropout)\n",
    "    \"qkv_bias\": False,          # Whether to use bias in QKV projections\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3349d",
   "metadata": {},
   "source": [
    "We will use the above configuration details to implement a GPT placeholder architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8710fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9c5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # A simple placeholder for a transformer block.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "    \n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # A simple placeholder for layer normalization.\n",
    "        # The parameters are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer norm does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a8f595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tok_emb = nn.Embedding(\n",
    "            num_embeddings=config['vocab_size'],\n",
    "            embedding_dim=config['emb_dim']\n",
    "        )\n",
    "        self.pos_emb = nn.Embedding(\n",
    "            num_embeddings=config['context_length'],\n",
    "            embedding_dim=config['emb_dim']\n",
    "        )\n",
    "        self.drop_emb = nn.Dropout(p=config['drop_rate'])\n",
    "\n",
    "        # Use a placeholder for `TransformerBlock` for now\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(config) for _ in range(config['n_layers'])]\n",
    "        )\n",
    "\n",
    "        # Use a placeholder for `LayerNorm` for now\n",
    "        self.final_norm = DummyLayerNorm(normalized_shape=config['emb_dim'])\n",
    "\n",
    "        # Output layer\n",
    "        self.out_head = nn.Linear(\n",
    "            in_features=config['emb_dim'],\n",
    "            out_features=config['vocab_size'],\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2646064",
   "metadata": {},
   "source": [
    "The `DummyGPTModel` class defines a simplified version of a GPT-like model. This is pretty straightforward and serves as a placeholder. The model architecture consists of:\n",
    "- token and positional embeddings\n",
    "- dropout layer\n",
    "- a series of transformer blocks (not implemented here, just a placeholder `DummyTransformerBlock`)\n",
    "- a final layer normalization (`DummyLayerNorm`)\n",
    "- a linear output layer to project the hidden states back to the vocabulary size for token prediction\n",
    "\n",
    "Any required parameters are passed through the `GPT_CONFIG_124M` dictionary.\n",
    "\n",
    "Next we need to prepare the input data and initialize a new GPT model instance to test the architecture.\n",
    "\n",
    "To start with, we will tokenize a batch of two text inputs for the GPT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "542f4636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([2, 4])\n",
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)  # Shape: (batch_size, seq_len)\n",
    "print(\"Input batch shape:\", batch.shape)\n",
    "print(\"Input batch:\\n\", batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62464dbf",
   "metadata": {},
   "source": [
    "Next, we can initialize the GPT model using the configuration dictionary and pass the tokenized inputs through the model to obtain the output logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f567c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output logits shape: torch.Size([2, 4, 50257])\n",
      "Output logits:\n",
      " tensor([[[ 1.0542, -1.1131,  1.0358,  ...,  1.2142, -0.2719,  0.5218],\n",
      "         [ 0.4354, -1.1167,  0.2321,  ..., -0.3016, -0.4041, -0.5582],\n",
      "         [ 0.4960, -0.9935,  0.2223,  ..., -0.4815,  0.0151, -0.2848],\n",
      "         [ 1.6846, -1.3228, -0.3068,  ...,  1.2541, -1.1059, -0.8833]],\n",
      "\n",
      "        [[ 1.1409, -0.2005,  0.9094,  ...,  0.3253, -0.3749,  0.8058],\n",
      "         [ 0.2844, -1.7189,  1.3266,  ..., -0.0942,  0.2244, -0.4697],\n",
      "         [ 0.3551, -0.4782,  0.3904,  ..., -0.7720,  0.2114,  0.7489],\n",
      "         [ 2.2828, -0.1362,  0.5286,  ...,  0.1818,  0.5542, -0.8470]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "logits = model(batch)\n",
    "print(\"Output logits shape:\", logits.shape)\n",
    "print(\"Output logits:\\n\", logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6311a017",
   "metadata": {},
   "source": [
    "The output tensor has\n",
    "- 2 rows corresponding to the 2 input sequences,\n",
    "- 4 tokens (context length) per sequence, and\n",
    "- 50,257-dimensional vectors representing the logits for each token in the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd40feee",
   "metadata": {},
   "source": [
    "## 4.2 Normalizing Activations with Layer Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06d17f",
   "metadata": {},
   "source": [
    "**Layer Normalization** is a technique used to stabilize and accelerate the training of deep neural networks by normalizing the activations within a layer. The main idea is to adjust the activations so that they have a mean of zero and a standard deviation of one, which helps to mitigate issues like internal covariate shift.\n",
    "\n",
    "In GPT-2 and modern transformer architectures, layer normalization is typically applied before or after the multi-head attentions and before the final output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261227a5",
   "metadata": {},
   "source": [
    "To begin with, we will first see how to implement layer normalization from scratch and how it works with tensors. Asssume we have a linear layer with 5 input features and 6 output features as well as two samples in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c181d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example batch shape: torch.Size([2, 5])\n",
      "Example batch:\n",
      " tensor([[ 1.5410, -0.2934, -2.1788,  0.5684, -1.0845],\n",
      "        [-1.3986,  0.4033,  0.8380, -0.7193, -0.4033]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Create a batch of 2 samples with 5 input features each\n",
    "batch_example = torch.randn(2, 5)\n",
    "print(\"Example batch shape:\", batch_example.shape)\n",
    "print(\"Example batch:\\n\", batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07d6ba02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after linear layer and ReLU shape: torch.Size([2, 6])\n",
      "Output after linear layer and ReLU:\n",
      " tensor([[0.8963, 1.2654, 0.6489, 0.0000, 0.3516, 0.0000],\n",
      "        [0.0000, 0.4422, 0.6083, 0.6321, 0.6686, 0.5418]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(\"Output after linear layer and ReLU shape:\", out.shape)\n",
    "print(\"Output after linear layer and ReLU:\\n\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2c9e9",
   "metadata": {},
   "source": [
    "Before we apply layer normalization, let's check the mean and variance of the output tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "469db0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of output (per sample):\n",
      " tensor([[0.5270],\n",
      "        [0.4822]], grad_fn=<MeanBackward1>)\n",
      "Variance of output (per sample):\n",
      " tensor([[0.2565],\n",
      "        [0.0622]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "\n",
    "print(\"Mean of output (per sample):\\n\", mean)\n",
    "print(\"Variance of output (per sample):\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650b665",
   "metadata": {},
   "source": [
    "The normalization is performed across the feature dimension (last dimension) for each sample in the batch. This means that for each sample, we compute the mean and variance of its features, and then normalize those features accordingly.\n",
    "\n",
    "Even later when we add layer normalization to our GPT model, which produces 3-dimensional tensors with shape `[batch_size, num_tokens, embedding_size]`, we can still use `dim=-1` for normalization across the last dimension (feature dimension) for each token in each sample.\n",
    "\n",
    "Next we can apply layer normalization to the output tensor. We will subtract the mean and divide by the standard deviation for each sample in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95e071c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after layer normalization shape: torch.Size([2, 6])\n",
      "Output after layer normalization:\n",
      " tensor([[ 0.7291,  1.4578,  0.2406, -1.0406, -0.3463, -1.0406],\n",
      "        [-1.9340, -0.1602,  0.5060,  0.6014,  0.7476,  0.2393]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean after layer normalization (per sample):\n",
      " tensor([[-3.9736e-08],\n",
      "        [ 1.1921e-07]], grad_fn=<MeanBackward1>)\n",
      "Variance after layer normalization (per sample):\n",
      " tensor([[1.],\n",
      "        [1.]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "print(\"Output after layer normalization shape:\", out_norm.shape)\n",
    "print(\"Output after layer normalization:\\n\", out_norm)\n",
    "\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Mean after layer normalization (per sample):\\n\", mean)\n",
    "print(\"Variance after layer normalization (per sample):\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0e074f",
   "metadata": {},
   "source": [
    "The output after layer normalization now contains features that have a mean close to 0 and variance close to 1 for each sample in the batch, demonstrating the effect of layer normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c3ee7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean after layer normalization (per sample):\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance after layer normalization (per sample):\n",
      " tensor([[1.],\n",
      "        [1.]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Better readability\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean after layer normalization (per sample):\\n\", mean)\n",
    "print(\"Variance after layer normalization (per sample):\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbcfa8e",
   "metadata": {},
   "source": [
    "Applying the same idea, we now can implement a `LayerNorm` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07102a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a2b9a7",
   "metadata": {},
   "source": [
    "The `eps` variable is used to prevent division by zero in case the variance is extremely small.\n",
    "\n",
    "The `scale` and `shift` parameters are trainable parameters (of the same dimension as the input) that the LLM automatically adjusts during training if it is determined that doing so would improve the model's performance on its training task, allowing the model to learn appropriate scaling and shifting that best suit the data it is processing.\n",
    "\n",
    "In the variance calculation, we use `unbiased=False` to compute the population variance ($\\frac{\\sum_i(x_i - \\mu)^2}{n}$) instead of the sample variance ($\\frac{\\sum_i(x_i - \\mu)^2}{n-1}$) where $n$ is the sample size (here, the number of features). This decision results in a *biased estimate* of the variance. For LLMs, where the embedding size (number of features) is typically large, the difference between the biased and unbiased estimates becomes negligible. \n",
    "\n",
    "We go with the biased estimate which is what GPT-2 uses as well for computational efficiency and simplicity so that our method is compatible with the pretrained weights later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e68c6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the LayerNorm class\n",
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97e0e0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of example batch (per sample):\n",
      " tensor([[-0.2895],\n",
      "        [-0.2560]])\n",
      "Variance of example batch (per sample):\n",
      " tensor([[1.6577],\n",
      "        [0.6347]])\n",
      "Mean after LayerNorm (per sample):\n",
      " tensor([[0.0000],\n",
      "        [0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance after LayerNorm (per sample):\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean_example = batch_example.mean(dim=-1, keepdim=True)\n",
    "var_example = batch_example.var(dim=-1, keepdim=True, unbiased=False)\n",
    "print(\"Mean of example batch (per sample):\\n\", mean_example)\n",
    "print(\"Variance of example batch (per sample):\\n\", var_example)\n",
    "\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, keepdim=True, unbiased=False)\n",
    "print(\"Mean after LayerNorm (per sample):\\n\", mean)\n",
    "print(\"Variance after LayerNorm (per sample):\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6af7a1",
   "metadata": {},
   "source": [
    "*Batch normalization* normalizes across the batch dimension, while *layer normalization* normalizes across the feature dimension for each individual sample.\n",
    "\n",
    "LLMs often require significant computational resources, and the available hardware or the specific use case can dictate the batch size during training or inference. Since layer normalization normalizes each sample independently of the batch size, it is more flexible and can handle varying batch sizes without affecting the normalization process. This is beneficial for distributed training or when deploying models in environments where resources are limited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c38f49",
   "metadata": {},
   "source": [
    "## 4.3 Implementing a Feed-Forward Network with GELU Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e44da5a",
   "metadata": {},
   "source": [
    "Besides the traditional ReLU activation function, LLMs often use the *Gaussian Error Linear Unit (GELU)* activation function and *Swish-gated Linear Unit (SwiGLU)* activation function in their feed-forward networks (FFNs) for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7430a8",
   "metadata": {},
   "source": [
    "For GELU, the exact formula is:\n",
    "$$\n",
    "\\text{GELU}(x) = x \\cdot \\Phi(x)\n",
    "$$\n",
    "where $\\Phi(x)$ is the cumulative distribution function of the standard Gaussian distribution. In practice, an efficient approximation is often used:\n",
    "$$\n",
    "\\text{GELU}(x) \\approx 0.5 \\cdot x \\left(1 + \\tanh\\left(\\sqrt{\\frac{2}{\\pi}} \\left(x + 0.044715x^3\\right)\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e63644cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python implementation of GELU activation function\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e9a4526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visual comparison of ReLU and GELU\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu = GELU()\n",
    "relu = nn.ReLU()\n",
    "\n",
    "# sample data\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu = gelu(x)\n",
    "y_relu = relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], ['GELU', 'ReLU'])):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(label)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d104bb",
   "metadata": {},
   "source": [
    "Compared to ReLU, GELU provides a smoother transition for negative inputs, which can help with gradient flow during training and lead to better performance in deep networks.\n",
    "\n",
    "Next, we will use the GELU function to implement a small feed-forward network (FFN) module commonly used in transformer architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01f713d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(config['emb_dim'], 4 * config['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * config['emb_dim'], config['emb_dim']),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cf5eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n",
      "Output shape from FeedForward network: torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding dimension:\", GPT_CONFIG_124M['emb_dim'])\n",
    "\n",
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "# input shape: [batch_size, num_token, emb_dim]\n",
    "x = torch.rand(2, 3, 768)\n",
    "\n",
    "out = ffn(x)\n",
    "print(\"Output shape from FeedForward network:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d728033",
   "metadata": {},
   "source": [
    "The `FeedForward` class enhances the model's ability to learn from and generalize the data. This expansion is followed by a nonlinear GELU activation and then a contraction back to the original embedding size for exploiting complex patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f33afc2",
   "metadata": {},
   "source": [
    "## 4.4 Adding Shortcut Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4389a2f5",
   "metadata": {},
   "source": [
    "A shortcut connection creates an alternative shorter path for the gradient to flow through the network during backpropagation. This helps to mitigate the vanishing gradient problem, allowing gradients to reach earlier layers more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fec99c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU()),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output  # Apply shortcut connection\n",
    "            else:\n",
    "                x = layer_output  # No shortcut, just use the layer output\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e88e8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target is to the output\n",
    "    loss = nn.MSELoss()\n",
    "    loss_val = loss(output, target)\n",
    "\n",
    "    # Backward pass\n",
    "    loss_val.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee661d9",
   "metadata": {},
   "source": [
    "Let's try a neural network without shortcut connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37a9879b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.0021742500830441713\n",
      "layers.1.0.weight has gradient mean of 0.0018201650818809867\n",
      "layers.2.0.weight has gradient mean of 0.0023985703010112047\n",
      "layers.3.0.weight has gradient mean of 0.01912502758204937\n",
      "layers.4.0.weight has gradient mean of 0.26376065611839294\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "layer_sizes = [3, 3, 3, 3, 3 ,1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes=layer_sizes,\n",
    "    use_shortcut=False\n",
    ")\n",
    "\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc64323",
   "metadata": {},
   "source": [
    "As we can see, without shortcut connections, the gradients become smaller as we progress from the last layer (`layer.4`) to the first layer (`layer.0`). This indicates that the gradients are vanishing, which can hinder effective learning in deeper networks.\n",
    "\n",
    "Now let's add shortcut connections to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50133b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.010206019505858421\n",
      "layers.1.0.weight has gradient mean of 0.009498980827629566\n",
      "layers.2.0.weight has gradient mean of 0.0024669563863426447\n",
      "layers.3.0.weight has gradient mean of 0.025129124522209167\n",
      "layers.4.0.weight has gradient mean of 0.09313038736581802\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes=layer_sizes,\n",
    "    use_shortcut=True\n",
    ")\n",
    "\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfcbbf4",
   "metadata": {},
   "source": [
    "The last layer (`layer.4`) still has a relatively large gradient, but the earlier layers now have significantly larger gradients compared to the network without shortcut connections. This demonstrates that shortcut connections help preserve gradient magnitude across layers, facilitating better learning in deep networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5efee3",
   "metadata": {},
   "source": [
    "## 4.5 Connecting Attention and Linear Layers in a Transformer Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fbd779",
   "metadata": {},
   "source": [
    "We now have all the necessary components to build a complete transformer block by connecting the multi-head attention layer and the feed-forward network with layer normalization and shortcut connections, and this fundamental buliding block can be stacked multiple times to create a deep transformer architecture like GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96876f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MultiHeadAttention class we defined in Chapter 3\n",
    "from llms_from_scratch.ch03 import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "572fcbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        # Same as before\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=config['emb_dim'],\n",
    "            d_out=config['emb_dim'],\n",
    "            context_length=config['context_length'],\n",
    "            num_heads=config['n_heads'],\n",
    "            dropout=config['drop_rate'],\n",
    "            qkv_bias=config['qkv_bias']\n",
    "        )\n",
    "\n",
    "        # Feed-forward network\n",
    "        self.ff = FeedForward(config)\n",
    "        # Layer normalization layers\n",
    "        self.ln1 = LayerNorm(config['emb_dim'])\n",
    "        self.ln2 = LayerNorm(config['emb_dim'])\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=config['drop_rate'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.ln1(x)\n",
    "        x = self.att(x) # Shape: [batch_size, seq_len, emb_dim]\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut # Apply shortcut connection\n",
    "\n",
    "        # Shortcut connection for feed-forward network\n",
    "        shortcut = x\n",
    "        x = self.ln2(x)\n",
    "        x = self.ff(x)  # Shape: [batch_size, seq_len, emb_dim]\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut # Apply shortcut connection\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb539e2",
   "metadata": {},
   "source": [
    "Layer normalization is applied before each of the multi-head attention and feed-forward network sub-layers, and dropout is used after each sub-layer to prevent overfitting. This is known as *Pre-LayerNorm*.\n",
    "\n",
    "Older transformer architectures used *Post-LayerNorm*, where layer normalization is applied after the self-attention and feed-forward sub-layers. However, Pre-LayerNorm has been found to be more stable during training, especially for deeper networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "991756cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "# Test the TransformerBlock\n",
    "torch.manual_seed(0)\n",
    "x = torch.rand(2, 4, 768)  # Example input: batch_size=2, num_token=4, emb_dim=768\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a764d7",
   "metadata": {},
   "source": [
    "As we can see, the transformer block maintains the input shape in its output, indicating that the transformer architecture processes sequences of data without altering their shape throughout the network. This property is crucial for tasks involving sequential data, such as natural language processing, where the sequence length must be preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a801730",
   "metadata": {},
   "source": [
    "## 4.6 Coding the GPT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70afcaa",
   "metadata": {},
   "source": [
    "Now we can replace the `DummyTransformerBlock` and `DummyLayerNorm` in our GPT model with the actual `TransformerBlock` and `LayerNorm` implementations to create a functional GPT architecture.\n",
    "\n",
    "Note that the transformer block is repeated multiple times; in the case of the smallest GPT-2 model, it is repeated 12 times to form a deep network capable of learning complex patterns in text data. This corresponding to the `n_layers` parameter in the `GPT_CONFIG_124M` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79f3d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration for GPT-2 124M model:\n",
      " {'vocab_size': 50257, 'context_length': 1024, 'emb_dim': 768, 'n_heads': 12, 'n_layers': 12, 'drop_rate': 0.1, 'qkv_bias': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"Configuration for GPT-2 124M model:\\n\", GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07d2c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tok_emb = nn.Embedding(\n",
    "            num_embeddings=config['vocab_size'],\n",
    "            embedding_dim=config['emb_dim']\n",
    "        )\n",
    "        self.pos_emb = nn.Embedding(\n",
    "            num_embeddings=config['context_length'],\n",
    "            embedding_dim=config['emb_dim']\n",
    "        )\n",
    "        self.drop_emb = nn.Dropout(p=config['drop_rate'])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(config) for _ in range(config['n_layers'])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(emb_dim=config['emb_dim'])\n",
    "\n",
    "        self.out_head = nn.Linear(\n",
    "            in_features=config['emb_dim'],\n",
    "            out_features=config['vocab_size'],\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        # index shape: [batch_size, seq_len] or [batch_size, num_tokens]\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "\n",
    "        # Token and positional embeddings\n",
    "        tok_embeds = self.tok_emb(in_idx)  # Shape: [batch_size, seq_len, emb_dim]\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))  # Shape: [seq_len, emb_dim]\n",
    "        x = tok_embeds + pos_embeds  # Shape: [batch_size, seq_len, emb_dim]\n",
    "\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)  # Shape: [batch_size, seq_len, emb_dim]\n",
    "        x = self.final_norm(x)  # Shape: [batch_size, seq_len, emb_dim]\n",
    "        logits = self.out_head(x)  # Shape: [batch_size, seq_len, vocab_size]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5067eb7b",
   "metadata": {},
   "source": [
    "Remind that the embedding layers (`tok_emb` and `pos_emb`) are responsible for converting input token indices into dense vector representations and adding positional information to these embeddings, respectively. These layers are crucial for the model to understand the context and order of tokens in the input sequence, as we discussed in Chapter 2.\n",
    "\n",
    "Now we can initialize a 124M GPT-2 model with the `GPT_CONFIG_124M` configuration dictionary we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b031d83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([2, 4])\n",
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output logits shape: torch.Size([2, 4, 50257])\n",
      "Output logits:\n",
      " tensor([[[-1.1000,  0.5460,  0.5332,  ...,  0.4144, -0.1159,  0.1868],\n",
      "         [-0.1678, -0.1384,  0.0151,  ...,  0.4356, -0.0620,  0.3977],\n",
      "         [-0.1707,  0.0207, -0.1978,  ..., -0.0503,  0.3358, -0.4299],\n",
      "         [-0.1184, -0.4138,  0.2432,  ...,  1.2942,  0.1587, -0.8207]],\n",
      "\n",
      "        [[-0.5338,  0.2238,  0.5445,  ...,  0.0741, -0.7147,  0.0675],\n",
      "         [-0.1699, -0.0242, -0.5727,  ...,  0.4784, -0.4581,  0.6214],\n",
      "         [-0.6074, -0.0871, -0.3612,  ..., -0.2842,  0.1463,  0.6657],\n",
      "         [-0.2279, -0.1704,  0.6844,  ..., -0.3375, -0.0054, -0.3893]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch shape:\", batch.shape)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput logits shape:\", out.shape)\n",
    "print(\"Output logits:\\n\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ce190",
   "metadata": {},
   "source": [
    "Using the `numel()` method (short for \"number of elements\"), we can check the total number of parameters in the GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff9e0c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in GPT model: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters in GPT model: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a61db5",
   "metadata": {},
   "source": [
    "Instead of 124M parameters, we get 163M parameters. This discrepancy arises because of the concept of *tying weights* which was used in the original GPT-2 implementation. Weight tying means that the original GPT-2 architecture reuses the weights from the token embedding layer in its output layer, by setting `self.out_head.weight = self.tok_emb.weight` in the model's initialization. This effectively reduces the total number of unique parameters in the model, as the same weights are used for both embedding and output projection.\n",
    "\n",
    "To understand this better, let's check those weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fbc3ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output head layer shape:     torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output head layer shape:    \", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93114327",
   "metadata": {},
   "source": [
    "- The token embedding layer projects the 50,257-dimensional one-hot encoded input tokens into 768-dimensional dense embedding representations.\n",
    "- The output head layer projects the 768-dimensional hidden states back to the 50,257-dimensional vocabulary space for token prediction so that we can convert these back into words.\n",
    "\n",
    "This is why the embedding and output layers have the same number of weight parameters.\n",
    "\n",
    "If we apply weight tying in our GPT model by setting `model.out_head.weight = model.tok_emb.weight` after initializing the model, we can subtract the number of parameters in the output head from the total parameter count to get the correct number of unique parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a3bd00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique parameters in GPT-2 model with weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Total number of unique parameters in GPT-2 model with weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ce299a",
   "metadata": {},
   "source": [
    "Weight tying reduces the overall memory footprint and computational complexity of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7215b3a9",
   "metadata": {},
   "source": [
    "Finally, we can also compute the memory requirements of our 163M-parameter GPT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc229bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory required for GPT model parameters: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total size in bytes (assuming float32, 4 bytes per parameter)\n",
    "total_size_bytes = total_params * 4\n",
    "\n",
    "# Convert to megabytes\n",
    "total_size_mb = total_size_bytes / (1024 ** 2)\n",
    "print(f\"Total memory required for GPT model parameters: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a646673",
   "metadata": {},
   "source": [
    "Therefore, assuming each parameter is stored as a 32-bit floating-point number (4 bytes), our GPT model would require approximately 651.83 MB of memory to store all its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd26361",
   "metadata": {},
   "source": [
    "## 4.7 Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2792964",
   "metadata": {},
   "source": [
    "The GPT model generates text given an input context. With each iteration, the input context grows allowing the model to generate coherent and contextually relevant text.\n",
    "\n",
    "In the following `generate_text_simple` function, we will implement greedy decoding to generate text from the GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfc3c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, num_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # e.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions:\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Focus only on the last time step\n",
    "        # logits shape: (batch_size, num_tokens, vocab_size) becomes (batch_size, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probs = torch.softmax(logits, dim=-1) # Shape: (batch_size, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab dimension with the highest probability (greedy decoding)\n",
    "        idx_next = torch.argmax(probs, dim=-1, keepdim=True)  # Shape: (batch_size, 1)\n",
    "\n",
    "        # Append the sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # Shape: (batch_size, num_tokens + 1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04698f7",
   "metadata": {},
   "source": [
    "In practice, the softmax step is redundant since the position with the highest score in the softmax output tensor is the same position in the logit tensor.\n",
    "\n",
    "The *greedy decoding* strategy selects the token with the highest probability at each step, but it may not always produce the most diverse or contextually rich text. More advanced techniques like beam search or sampling methods can be used to improve the quality of generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f8f6647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded start context: [15496, 11, 314, 716]\n",
      "Encoded tensor shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "start_context = \"Hello, I am\"\n",
    "\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"Encoded start context:\", encoded)\n",
    "\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # Shape: (1, num_tokens) # Add batch dimension\n",
    "print(\"Encoded tensor shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da5abf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated token indices: tensor([[15496,    11,   314,   716, 42134, 43541, 42296, 37511, 45799,  7309]])\n",
      "Generated output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() # Set the model to evaluation mode to disable dropout\n",
    "\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "print(\"Generated token indices:\", out)\n",
    "print(\"Generated output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d372b344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: Hello, I am PracticesAmidFUNLastly sprinkle plastic\n"
     ]
    }
   ],
   "source": [
    "# Remove batch dimension and decode the generated tokens\n",
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(\"Generated text:\", decoded_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

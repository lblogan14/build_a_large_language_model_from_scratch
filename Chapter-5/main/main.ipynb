{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "885a971a",
   "metadata": {},
   "source": [
    "# Chapter 5: Pretraining on Unlabeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d06ed2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.8\n",
      "numpy version: 2.4.0\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.9.1\n",
      "tensorflow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    'matplotlib',\n",
    "    'numpy',\n",
    "    'tiktoken',\n",
    "    'torch',\n",
    "    'tensorflow'\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719fcc8f",
   "metadata": {},
   "source": [
    "## 5.1 Evaluating Generative Text Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c55a15",
   "metadata": {},
   "source": [
    "### 5.1.1 Using GPT to Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113d49df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize GPT model from Chapter 4\n",
    "import torch\n",
    "from llms_from_scratch.ch04 import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 256,  # Shortened context length (original length: 1024)\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()  # Set the model to evaluation mode to disable dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e892f",
   "metadata": {},
   "source": [
    "We apply 0.1 drop rate above but it is common to train LLMs without dropout nowadays.\n",
    "\n",
    "Modern LLMs also do not use bias vectors in the `nn.Linear` layers for the query, key and value matrices: `\"qkv_bias\"=False`.\n",
    "\n",
    "We reduced the context length from 1024 to 256 to reduce computational resources for training.\n",
    "\n",
    "We will also use the `generate_text_simple` function defined in Chapter 4 to generate text from our trained GPT model, with two utility functions, `text_to_token_ids` and `token_ids_to_text`, to convert between text and token IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc65a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from llms_from_scratch.ch04 import generate_text_simple\n",
    "\n",
    "# Utility functions for text-token conversion\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # Remove batch dimension\n",
    "\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d14ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Initi Nileuriynski foreNe respective dip lac arsen\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e82831",
   "metadata": {},
   "source": [
    "### 5.1.2 Calculating the Text Generation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f14ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([2, 3])\n",
      "Inputs:\n",
      " tensor([[16833,  3626,  6100],\n",
      "        [   40,  1107,   588]])\n"
     ]
    }
   ],
   "source": [
    "# Two input batches\n",
    "input_texts = [\n",
    "    \"every effort moves\",\n",
    "    \"I really like\"\n",
    "]\n",
    "inputs = torch.cat([text_to_token_ids(text, tokenizer) for text in input_texts], dim=0)\n",
    "print(\"Inputs shape:\", inputs.shape)  # Should be (2, sequence_length)\n",
    "print(\"Inputs:\\n\", inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe2b1158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets shape: torch.Size([2, 3])\n",
      "Targets:\n",
      " tensor([[ 3626,  6100,   345],\n",
      "        [ 1107,   588, 11311]])\n"
     ]
    }
   ],
   "source": [
    "# targets are the inputs shifted by one position\n",
    "target_texts = [\n",
    "    \" effort moves you\",\n",
    "    \" really like chocolate\"\n",
    "]\n",
    "targets = torch.cat([text_to_token_ids(text, tokenizer) for text in target_texts], dim=0)\n",
    "print(\"Targets shape:\", targets.shape)  # Should be (2, sequence_length)\n",
    "print(\"Targets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a529a",
   "metadata": {},
   "source": [
    "Now we feed `inputs` to the model to get the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c6db3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient calculation\n",
    "    logits = model(inputs)\n",
    "\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "print(\"Logits shape:\", logits.shape)  # Should be (2, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69622550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted token IDs shape: torch.Size([2, 3, 1])\n",
      "Predicted token IDs:\n",
      " tensor([[[47766],\n",
      "         [49992],\n",
      "         [16634]],\n",
      "\n",
      "        [[28961],\n",
      "         [23252],\n",
      "         [ 6895]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "print(\"Predicted token IDs shape:\", token_ids.shape)  # Should be (2, num_tokens, 1)\n",
    "print(\"Predicted token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c252ec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Predicted batch 1:  Lydia shockinglyppo\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Predicted batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed92281",
   "metadata": {},
   "source": [
    "We want to evaluate the performance of the model's generated text numerically via a loss function so that we can measure \"how far\" the generated tokens are from the correct predictions (the targets).\n",
    "\n",
    "The model training aims to increase the softmax probability in the index positions corresponding to the correct target token IDs. This probability is also used in the evaluation metric we will implement next to numerically assess the model's generated outputs.\n",
    "\n",
    "For each of the two input texts, we can check the initial softmax probabilities corresponding to the target tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eef6b680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax probabilities for target tokens in batch 1: tensor([1.4901e-05, 6.1409e-05, 1.8651e-05])\n",
      "Softmax probabilities for target tokens in batch 2: tensor([8.8184e-06, 2.3608e-05, 2.9832e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probs_1 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Softmax probabilities for target tokens in batch 1:\", target_probs_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probs_2 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Softmax probabilities for target tokens in batch 2:\", target_probs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e72725b",
   "metadata": {},
   "source": [
    "We want to maximize all these values, bringing them close to a probability of 1.0.\n",
    "\n",
    "In mathematical optimization, we usually maximize the logarithm of the probability instead of the probability itself, as it is numerically more stable and easier to work with. Thus, we will maximize the sum of the log probabilities of the target tokens across all positions and both input texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e267948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probabilities of target tokens: tensor([-11.1141,  -9.6979, -10.8896, -11.6387, -10.6539, -10.4199])\n"
     ]
    }
   ],
   "source": [
    "log_probs = torch.log(torch.cat((target_probs_1, target_probs_2)))\n",
    "print(\"Log probabilities of target tokens:\", log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5397cb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average log probability of target tokens: tensor(-10.7357)\n"
     ]
    }
   ],
   "source": [
    "# Calculate average log probability\n",
    "avg_log_probs = torch.mean(log_probs)\n",
    "print(\"Average log probability of target tokens:\", avg_log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fbb5b2",
   "metadata": {},
   "source": [
    "The goal is to get the average log probability as close to 0 as possible (since log(1) = 0).\n",
    "\n",
    "In deep learning, instead of maximizing the average log probability, we usually minimize the *negative average log probability*, which is known as the *cross-entropy loss*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f812376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative average log probability (cross-entropy loss): tensor(10.7357)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probs = avg_log_probs * -1\n",
    "print(\"Negative average log probability (cross-entropy loss):\", neg_avg_log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0a128",
   "metadata": {},
   "source": [
    "The **cross-entropy loss** measures the difference between two probability distributions, the true distribution of labels (tokens in a dataset) and the predicted distribution from a model (token probabilities generated by an LLM).\n",
    "\n",
    "We can get the same results using the built-in `cross_entropy` function from PyTorch. Before we apply it, we need to check the shapes of the logits and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0cb12e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)   # Shape: (2, num_tokens, vocab_size)\n",
    "print(\"Targets shape:\", targets.shape) # Shape: (2, num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87f3a3",
   "metadata": {},
   "source": [
    "To apply `cross_entropy`, we need to flatten these tensors by combining them over the batch dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b71acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits shape: torch.Size([6, 50257])\n",
      "Flattened targets shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)  # Shape: (2 * num_tokens, vocab_size)\n",
    "targets_flat = targets.flatten()    # Shape: (2 * num_tokens)\n",
    "\n",
    "print(\"Flattened logits shape:\", logits_flat.shape)\n",
    "print(\"Flattened targets shape:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8bb34",
   "metadata": {},
   "source": [
    "The `cross_entropy` function will automatically take care of applying the softmax and log-probability over those token indices in the logits that are to be maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f305896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropy loss: tensor(10.7357)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(\"Cross-entropy loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aae07c",
   "metadata": {},
   "source": [
    "**Perplexity** is a measure used alongside cross-entropy loss to evaluate the performance of models in tasks like language modeling.\n",
    "\n",
    "Perplexity measures how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset. A *lower* perplexity indicates that the model predictions are closer to the actual distribution.\n",
    "\n",
    "Perplexity is calculated as the exponentiation of the cross-entropy loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46ef9389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: tensor(45967.7305)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(\"Perplexity:\", perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf205f",
   "metadata": {},
   "source": [
    "Perplexity is considered more interpretable than the raw loss because it signifies the effective vocabulary size about which the model is uncertain at each step.\n",
    "\n",
    "For example, given the current vocabulary size of 50,257 tokens, this perplexity value would translate to the model being unsure about which among 45968 tokens in the vocabulary to generate as the next token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5265a8",
   "metadata": {},
   "source": [
    "### 5.1.3 Calculating the Training and Validation Set Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf53c9d",
   "metadata": {},
   "source": [
    "For demo purposes, we will use a very small text dataset, the \"The Verdict\" short story in Chapter 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f07fedff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in dataset: 20479\n",
      "Total tokens in dataset: 5145\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "filepath = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    text_data = response.text\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text_data)\n",
    "else:\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        text_data = f.read()\n",
    "\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f\"Total characters in dataset: {total_characters}\")\n",
    "print(f\"Total tokens in dataset: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67a5e8",
   "metadata": {},
   "source": [
    "Next we divide the dataset into training and validation sets and we will use the dataloader defined in Chapter 2 to iterate over these datasets and calculate the average loss on both sets.\n",
    "\n",
    "We will train the model with training data presented in similarly sized chunks for simplicity and efficiency. However, in practice, it can be beneficial to train an LLM with variable-length inputs to help the LLM to better generalize across different types of inputs when it is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d635f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llms_from_scratch.ch02 import create_dataloader_v1\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Train/Val ratio\n",
    "train_ratio = 0.9\n",
    "split_idx = int(total_characters * train_ratio)\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68772a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader_v1(\n",
    "    txt=train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    txt=val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "576b8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M['context_length']:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`.\")\n",
    "    \n",
    "if total_tokens * (1 - train_ratio) < GPT_CONFIG_124M['context_length']:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2964d8",
   "metadata": {},
   "source": [
    "We used a relatively small batch size of 2 to reduce computational resource requirements for this demo. In practice, larger batch sizes (e.g., 128, 256, or even 512) are often used to stabilize training and improve convergence.\n",
    "\n",
    "For example, Llama 2 7B was trained with a batch size of 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78468a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "batch 1 - Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "batch 2 - Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "batch 3 - Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "batch 4 - Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "batch 5 - Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "batch 6 - Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "batch 7 - Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "batch 8 - Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "batch 9 - Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "Validation loader:\n",
      "batch 1 - Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for i, (x,y) in enumerate(train_loader):\n",
    "    print(f\"batch {i+1} - Input batch shape: {x.shape}, Target batch shape: {y.shape}\")\n",
    "\n",
    "print(\"Validation loader:\")\n",
    "for i, (x,y) in enumerate(val_loader):\n",
    "    print(f\"batch {i+1} - Input batch shape: {x.shape}, Target batch shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "061aed1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in training loader: 4608\n",
      "Total tokens in validation loader: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "# Sanity check the token sizes are in the expected ballpark\n",
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(f\"Total tokens in training loader: {train_tokens}\")\n",
    "print(f\"Total tokens in validation loader: {val_tokens}\")\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba99a42f",
   "metadata": {},
   "source": [
    "Next we need a utility function `calc_loss_batch` to calculate the cross-entropy loss for a given batch of input and target token IDs. In addition, we will have `calc_loss_loader` to compute the loss over all the batches in a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca2e1487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1),  # Flatten the logits to shape (batch_size * seq_length, vocab_size)\n",
    "        target_batch.flatten()  # Flatten the targets to shape (batch_size * seq_length)\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(dataloader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(dataloader) == 0:\n",
    "        return float('nan')\n",
    "\n",
    "    elif num_batches is None:\n",
    "        # Use all batches in the dataloader\n",
    "        num_batches = len(dataloader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the dataloader\n",
    "        # if num_batches exceeds the number of batches in the dataloader\n",
    "        num_batches = min(num_batches, len(dataloader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(dataloader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adf1fbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training set loss: 10.9821\n",
      "Validation set loss: 10.9975\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Training set loss: {train_loss:.4f}\")\n",
    "print(f\"Validation set loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b90bdc",
   "metadata": {},
   "source": [
    "## 5.2 Training an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39cc21f",
   "metadata": {},
   "source": [
    "We will implement a simple training loop to train our GPT model on the training dataset and evaluate it on the validation dataset after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a6447ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    \n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \")) # Compact print format\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a4a2f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        device,\n",
    "        num_epochs,\n",
    "        eval_freq,\n",
    "        eval_iter,\n",
    "        start_context,\n",
    "        tokenizer\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    track_tokens_seen = []\n",
    "    tokens_seen = 0\n",
    "    global_step = -1\n",
    "\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set the model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # Reset loss gradients from previous batch iteration\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "\n",
    "                print(f\"Epoch {epoch+1} (Step {global_step:06d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542872c8",
   "metadata": {},
   "source": [
    "*Adam* optimizer is widely used for training deep learning models. However, we will use the *AdamW* optimizer, a variant of Adam that improves model complexity and prevent overfitting by penalizing large weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb5046a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000000): Train loss 9.844, Val loss 10.086\n",
      "Epoch 1 (Step 000005): Train loss 8.093, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Epoch 2 (Step 000010): Train loss 6.754, Val loss 7.071\n",
      "Epoch 2 (Step 000015): Train loss 6.067, Val loss 6.650\n",
      "Every effort moves you.                                                 \n",
      "Epoch 3 (Step 000020): Train loss 5.814, Val loss 6.519\n",
      "Epoch 3 (Step 000025): Train loss 5.655, Val loss 6.485\n",
      "Every effort moves you                                                  \n",
      "Epoch 4 (Step 000030): Train loss 5.650, Val loss 6.571\n",
      "Epoch 4 (Step 000035): Train loss 5.021, Val loss 6.485\n",
      "Every effort moves you he had a I had a a--                                          \n",
      "Epoch 5 (Step 000040): Train loss 4.626, Val loss 6.476\n",
      "Every effort moves you, and in the picture. Gisburn's the picture. Gisburn's, and--and--and, I had a little a little to the last I had the last--and it--and a, and it--and the picture\n",
      "Epoch 6 (Step 000045): Train loss 4.276, Val loss 6.280\n",
      "Epoch 6 (Step 000050): Train loss 3.576, Val loss 6.273\n",
      "Every effort moves you know to see on a little a little of the picture--as the picture--as, and--as, and in an unusual to see a little of his pictures. \"--as if he had been a, and were, and I had\n",
      "Epoch 7 (Step 000055): Train loss 3.163, Val loss 6.251\n",
      "Epoch 7 (Step 000060): Train loss 2.762, Val loss 6.277\n",
      "Every effort moves you know. Gisburn--and--I felt nervous a good that I was.     \"I was his pictures--and I had been his pictures--I had been the donkey, the donkey.      \n",
      "Epoch 8 (Step 000065): Train loss 2.466, Val loss 6.246\n",
      "Epoch 8 (Step 000070): Train loss 1.996, Val loss 6.320\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on the background of the house.\"  \"Oh, I felt to see a smile behind his close grayish beard--as if he had the donkey.   \"Oh,\n",
      "Epoch 9 (Step 000075): Train loss 1.573, Val loss 6.336\n",
      "Epoch 9 (Step 000080): Train loss 1.277, Val loss 6.359\n",
      "Every effort moves you in the picture.  \"Oh, with a deprecating laugh--so it was no great surprise to me to the cigars you in the height of his glory, he had dropped his painting, the donkey. \"There were, I found\n",
      "Epoch 10 (Step 000085): Train loss 0.973, Val loss 6.420\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  \"Oh, in the moment--as Jack himself, I had the sketch of the donkey. \"There were days when I\n",
      "Total training time: 1.60 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004,\n",
    "    weight_decay=0.1\n",
    ")\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Total training time: {execution_time_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "640d3481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot training and validation losses\n",
    "    ax1.plot(epochs_seen, train_losses, label='Training loss')\n",
    "    ax1.plot(epochs_seen, val_losses, label='Validation loss', linestyle='-.')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True)) # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny() # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel('Tokens seen')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36993bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccc8b7e",
   "metadata": {},
   "source": [
    "The model starts out generating incomprehensible text, but as training progresses, it begins to produce more coherent and contextually relevant outputs. However, given the small size of our dataset, the model starts to overfit after a few epochs, as indicated by the divergence between training and validation losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f318ad8",
   "metadata": {},
   "source": [
    "## 5.3 Decoding Strategies to Control Randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37059cec",
   "metadata": {},
   "source": [
    "The `generate_text_simple` function we defined in Chapter 4 uses a greedy decoding strategy, which selects the token with the highest probability at each step. While this approach is straightforward, it can lead to repetitive and less diverse text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc318af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inference_device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(inference_device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Generated text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170ee5d6",
   "metadata": {},
   "source": [
    "### 5.3.1 Temperature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94523a30",
   "metadata": {},
   "source": [
    "**Temperature scaling** is a technique used to add a probabilistic selection process to the next-token generation task.\n",
    "\n",
    "In the `generate_text_simple` function, we always sampled the token with the highest probability as the next token using `torch.argmax`, which is known as *greedy decoding*.\n",
    "\n",
    "To generate text with more variety, we can replace `torch.argmax` with a function that samples from a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4010eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo vocabulary\n",
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v:k for k,v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38e5cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c580c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy decoding selected token: 'forward' with probability 0.5721\n"
     ]
    }
   ],
   "source": [
    "# Greedy decoding\n",
    "probs = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probs).item()\n",
    "print(f\"Greedy decoding selected token: '{inverse_vocab[next_token_id]}' with probability {probs[next_token_id]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991a275",
   "metadata": {},
   "source": [
    "To implement a probalistic sampling process, we will replace `torch.argmax` with `torch.multinomial`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "243522dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilistic sampling selected token: 'toward' with probability 0.3576\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)  # For reproducibility\n",
    "next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "print(f\"Probabilistic sampling selected token: '{inverse_vocab[next_token_id]}' with probability {probs[next_token_id]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c04e04",
   "metadata": {},
   "source": [
    "The `torch.multinomial` function samples the next token proportional to its probability score. In other words, `'torward'` is the most likely token and will be selected by `multinomial` most of the time, but not all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f98c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sampled_tokens(probs):\n",
    "    torch.manual_seed(0)  # For reproducibility\n",
    "    sample = [torch.multinomial(probs, num_samples=1).item() for i in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probs))\n",
    "\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"Token: '{inverse_vocab[i]}', Frequency: {freq}, Estimated Probability: {freq/1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1abd8678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 'closer', Frequency: 50, Estimated Probability: 0.0500\n",
      "Token: 'every', Frequency: 1, Estimated Probability: 0.0010\n",
      "Token: 'effort', Frequency: 0, Estimated Probability: 0.0000\n",
      "Token: 'forward', Frequency: 562, Estimated Probability: 0.5620\n",
      "Token: 'inches', Frequency: 5, Estimated Probability: 0.0050\n",
      "Token: 'moves', Frequency: 0, Estimated Probability: 0.0000\n",
      "Token: 'pizza', Frequency: 0, Estimated Probability: 0.0000\n",
      "Token: 'toward', Frequency: 373, Estimated Probability: 0.3730\n",
      "Token: 'you', Frequency: 9, Estimated Probability: 0.0090\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23fd931",
   "metadata": {},
   "source": [
    "The word `\"forward\"` is sampled most of the time, but other tokens are also sampled occasionally, demonstrating the probabilistic nature of this sampling method.\n",
    "\n",
    "We can further control the distribution and selection process via a concept called *temperature scaling*.\n",
    "\n",
    "**Temperature scaling** divides the logits by a number greater than 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e554c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91714c",
   "metadata": {},
   "source": [
    "- Temperature > 1: more uniformly distributed token probabilities, leading to more diverse but potentially less coherent text.\n",
    "- Temperature < 1: more confident (sharper and more peaky) token probabilities, leading to more focused and coherent text but less diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc67fa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5] # [original, higher configuration, lower configuration]\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probs = [softmax_with_temperature(next_token_logits, temp) for temp in temperatures]\n",
    "\n",
    "# Plot\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, temp in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probs[i], bar_width, label=f\"Temperature = {temp}\")\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759394a",
   "metadata": {},
   "source": [
    "A temperature of 1 divides the logits by 1 before applying softmax, which leaves the original distribution unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fde68ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 'closer', Frequency: 0, Estimated Probability: 0.0000\n",
      "Token: 'every', Frequency: 0, Estimated Probability: 0.0000\n",
      "Token: 'effort', Frequency: 0, Estimated Probability: 0.0000\n",
      "Token: 'forward', Frequency: 984, Estimated Probability: 0.9840\n",
      "Token: 'inches', Frequency: 0, Estimated Probability: 0.0000\n",
      "Token: 'moves', Frequency: 0, Estimated Probability: 0.0000\n",
      "Token: 'pizza', Frequency: 0, Estimated Probability: 0.0000\n",
      "Token: 'toward', Frequency: 16, Estimated Probability: 0.0160\n",
      "Token: 'you', Frequency: 0, Estimated Probability: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# temperature = 0.1\n",
    "print_sampled_tokens(scaled_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7acdfaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 'closer', Frequency: 139, Estimated Probability: 0.1390\n",
      "Token: 'every', Frequency: 65, Estimated Probability: 0.0650\n",
      "Token: 'effort', Frequency: 43, Estimated Probability: 0.0430\n",
      "Token: 'forward', Frequency: 257, Estimated Probability: 0.2570\n",
      "Token: 'inches', Frequency: 75, Estimated Probability: 0.0750\n",
      "Token: 'moves', Frequency: 45, Estimated Probability: 0.0450\n",
      "Token: 'pizza', Frequency: 54, Estimated Probability: 0.0540\n",
      "Token: 'toward', Frequency: 231, Estimated Probability: 0.2310\n",
      "Token: 'you', Frequency: 91, Estimated Probability: 0.0910\n"
     ]
    }
   ],
   "source": [
    "# temperature = 5\n",
    "print_sampled_tokens(scaled_probs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92279e",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01901e32",
   "metadata": {},
   "source": [
    "Temperature scaling affects the entire probability distribution to increase the randomness of token selection. One downside of this approach is that it sometimes leads to grammatically incorrect or nonsensical text, especially when the temperature is set too high.\n",
    "\n",
    "**Top-k sampling**, when combined with probabilistic sampling and temperature scaling, can improve the text generation quality by limiting the selection to the top *k* most probable tokens.\n",
    "\n",
    "In top-k sampling, we can restrict the sampled tokens to the top-k most like tokens and exclude all other tokens from the selection process by masking their probabilities to zero before sampling.\n",
    "\n",
    "The top-k approach replaces all nonselected logits with `-inf` before applying softmax, effectively setting their probabilities to zero, and then the remaining probabilities are renormalized to sum to 1. This way, the sampling process only considers the top-k tokens, leading to more coherent and contextually relevant text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e7160a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top-3 token positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(f\"Top-{top_k} logits: {top_logits}\")\n",
    "print(f\"Top-{top_k} token positions: {top_pos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "026cc0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New logits after applying top-k sampling:\n",
      " tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1], # Identify logits less than the min of top-k logits\n",
    "    input=torch.tensor(float('-inf')),            # Assign -inf to those logits\n",
    "    other=next_token_logits                       # Retain original logits for top-k tokens\n",
    ")\n",
    "print(\"New logits after applying top-k sampling:\\n\", new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17191dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities after applying top-k sampling:\n",
      " tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax to turn new_logits into probabilities\n",
    "topk_probs = torch.softmax(new_logits, dim=0)\n",
    "print(\"Probabilities after applying top-k sampling:\\n\", topk_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ebd95a",
   "metadata": {},
   "source": [
    "### 5.3.3 Modifying the Text Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "014c049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(\n",
    "        model,\n",
    "        idx,\n",
    "        max_new_tokens,\n",
    "        context_size,\n",
    "        temperature=0.,\n",
    "        top_k=None,\n",
    "        eos_id=None\n",
    "):\n",
    "    # For-loop setup - same as before: get logits, and only focus on the last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Crop context if needed\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # Focus on the last time step\n",
    "\n",
    "        # NEW: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k logits\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                condition=logits < min_val,\n",
    "                input=torch.tensor(float('-inf')).to(logits.device),\n",
    "                other=logits\n",
    "            )\n",
    "\n",
    "        # NEW: Apply temperature scaling\n",
    "        if temperature > 0.:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # NEW: numerical stability fix\n",
    "            # - subtract row-wise max before applying softmax\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1) # Shape: (batch_size, context_size)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # Shape: (batch_size, 1)\n",
    "\n",
    "        # Otherwise: greedy decoding\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # Shape: (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            # Stop generating early if end-of-sequence token is generated\n",
    "            break\n",
    "\n",
    "        # Append sampled token to the sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # Shape: (batch_size, num_tokens + 1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95d61b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text with temperature scaling and top-k sampling:\n",
      " Every effort moves you found his eyes over that Mrs.\n",
      " \" the room, the tips laugh\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    temperature=1.4,\n",
    "    top_k=25\n",
    ")\n",
    "print(\"Generated text with temperature scaling and top-k sampling:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23782dc3",
   "metadata": {},
   "source": [
    "## 5.4 Loading and Saving Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model weights - `state_dict`\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model weights\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a2b4a0",
   "metadata": {},
   "source": [
    "We may also need to save the additional parameters used in the optimizer with the model weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f287706",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model and optimizer weights\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4528cc85",
   "metadata": {},
   "source": [
    "## 5.5 Loading Pretrained Weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c721eb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62113e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llms_from_scratch.ch05 import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")\n",
    "\n",
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())\n",
    "\n",
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adc940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf68bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b30ccaa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
